{"ast":null,"code":"// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { Column } from './column';\nimport { Schema } from './schema';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from './recordbatch';\nimport { RecordBatchReader } from './ipc/reader';\nimport { Struct } from './type';\nimport { selectColumnArgs, selectArgs } from './util/args';\nimport { isPromise, isIterable, isAsyncIterable } from './util/compat';\nimport { RecordBatchFileWriter, RecordBatchStreamWriter } from './ipc/writer';\nimport { distributeColumnsIntoRecordBatches, distributeVectorsIntoRecordBatches } from './util/recordbatch';\nimport { Chunked, StructVector } from './vector/index';\nexport class Table extends Chunked {\n  constructor(...args) {\n    let schema = null;\n\n    if (args[0] instanceof Schema) {\n      schema = args.shift();\n    }\n\n    let chunks = selectArgs(RecordBatch, args);\n\n    if (!schema && !(schema = chunks[0] && chunks[0].schema)) {\n      throw new TypeError('Table must be initialized with a Schema or at least one RecordBatch');\n    }\n\n    chunks[0] || (chunks[0] = new _InternalEmptyPlaceholderRecordBatch(schema));\n    super(new Struct(schema.fields), chunks);\n    this._schema = schema;\n    this._chunks = chunks;\n  }\n  /** @nocollapse */\n\n\n  static empty(schema = new Schema([])) {\n    return new Table(schema, []);\n  }\n  /** @nocollapse */\n\n\n  static from(input) {\n    if (!input) {\n      return Table.empty();\n    }\n\n    if (typeof input === 'object') {\n      let table = isIterable(input['values']) ? tableFromIterable(input) : isAsyncIterable(input['values']) ? tableFromAsyncIterable(input) : null;\n\n      if (table !== null) {\n        return table;\n      }\n    }\n\n    let reader = RecordBatchReader.from(input);\n\n    if (isPromise(reader)) {\n      return (async () => await Table.from((await reader)))();\n    }\n\n    if (reader.isSync() && (reader = reader.open())) {\n      return !reader.schema ? Table.empty() : new Table(reader.schema, [...reader]);\n    }\n\n    return (async opening => {\n      const reader = await opening;\n      const schema = reader.schema;\n      const batches = [];\n\n      if (schema) {\n        for await (let batch of reader) {\n          batches.push(batch);\n        }\n\n        return new Table(schema, batches);\n      }\n\n      return Table.empty();\n    })(reader.open());\n  }\n  /** @nocollapse */\n\n\n  static async fromAsync(source) {\n    return await Table.from(source);\n  }\n  /** @nocollapse */\n\n\n  static fromStruct(vector) {\n    return Table.new(vector.data.childData, vector.type.children);\n  }\n  /** @nocollapse */\n\n\n  static new(...cols) {\n    return new Table(...distributeColumnsIntoRecordBatches(selectColumnArgs(cols)));\n  }\n\n  get schema() {\n    return this._schema;\n  }\n\n  get length() {\n    return this._length;\n  }\n\n  get chunks() {\n    return this._chunks;\n  }\n\n  get numCols() {\n    return this._numChildren;\n  }\n\n  clone(chunks = this._chunks) {\n    return new Table(this._schema, chunks);\n  }\n\n  getColumn(name) {\n    return this.getColumnAt(this.getColumnIndex(name));\n  }\n\n  getColumnAt(index) {\n    return this.getChildAt(index);\n  }\n\n  getColumnIndex(name) {\n    return this._schema.fields.findIndex(f => f.name === name);\n  }\n\n  getChildAt(index) {\n    if (index < 0 || index >= this.numChildren) {\n      return null;\n    }\n\n    let field, child;\n    const fields = this._schema.fields;\n    const columns = this._children || (this._children = []);\n\n    if (child = columns[index]) {\n      return child;\n    }\n\n    if (field = fields[index]) {\n      const chunks = this._chunks.map(chunk => chunk.getChildAt(index)).filter(vec => vec != null);\n\n      if (chunks.length > 0) {\n        return columns[index] = new Column(field, chunks);\n      }\n    }\n\n    return null;\n  } // @ts-ignore\n\n\n  serialize(encoding = 'binary', stream = true) {\n    const Writer = !stream ? RecordBatchFileWriter : RecordBatchStreamWriter;\n    return Writer.writeAll(this).toUint8Array(true);\n  }\n\n  count() {\n    return this._length;\n  }\n\n  select(...columnNames) {\n    const nameToIndex = this._schema.fields.reduce((m, f, i) => m.set(f.name, i), new Map());\n\n    return this.selectAt(...columnNames.map(columnName => nameToIndex.get(columnName)).filter(x => x > -1));\n  }\n\n  selectAt(...columnIndices) {\n    const schema = this._schema.selectAt(...columnIndices);\n\n    return new Table(schema, this._chunks.map(({\n      length,\n      data: {\n        childData\n      }\n    }) => {\n      return new RecordBatch(schema, length, columnIndices.map(i => childData[i]).filter(Boolean));\n    }));\n  }\n\n  assign(other) {\n    const fields = this._schema.fields;\n    const [indices, oldToNew] = other.schema.fields.reduce((memo, f2, newIdx) => {\n      const [indices, oldToNew] = memo;\n      const i = fields.findIndex(f => f.name === f2.name);\n      ~i ? oldToNew[i] = newIdx : indices.push(newIdx);\n      return memo;\n    }, [[], []]);\n\n    const schema = this._schema.assign(other.schema);\n\n    const columns = [...fields.map((_f, i, _fs, j = oldToNew[i]) => j === undefined ? this.getColumnAt(i) : other.getColumnAt(j)), ...indices.map(i => other.getColumnAt(i))].filter(Boolean);\n    return new Table(...distributeVectorsIntoRecordBatches(schema, columns));\n  }\n\n}\n\nfunction tableFromIterable(input) {\n  const {\n    type\n  } = input;\n\n  if (type instanceof Struct) {\n    return Table.fromStruct(StructVector.from(input));\n  }\n\n  return null;\n}\n\nfunction tableFromAsyncIterable(input) {\n  const {\n    type\n  } = input;\n\n  if (type instanceof Struct) {\n    return StructVector.from(input).then(vector => Table.fromStruct(vector));\n  }\n\n  return null;\n}","map":{"version":3,"sources":["table.ts"],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA,SAAS,MAAT,QAAuB,UAAvB;AACA,SAAS,MAAT,QAA8B,UAA9B;AACA,SAAS,WAAT,EAAsB,oCAAtB,QAAkE,eAAlE;AAEA,SAAS,iBAAT,QAAkC,cAAlC;AACA,SAA4B,MAA5B,QAA0C,QAA1C;AACA,SAAS,gBAAT,EAA2B,UAA3B,QAA6C,aAA7C;AAEA,SAAS,SAAT,EAAoB,UAApB,EAAgC,eAAhC,QAAuD,eAAvD;AACA,SAAS,qBAAT,EAAgC,uBAAhC,QAA+D,cAA/D;AACA,SAAS,kCAAT,EAA6C,kCAA7C,QAAuF,oBAAvF;AACA,SAAiB,OAAjB,EAA0B,YAA1B,QAA+F,gBAA/F;AAsBA,OAAM,MAAO,KAAP,SACM,OADN,CACwB;AA8H1B,EAAA,WAAA,CAAY,GAAG,IAAf,EAA0B;AAEtB,QAAI,MAAM,GAAc,IAAxB;;AAEA,QAAI,IAAI,CAAC,CAAD,CAAJ,YAAmB,MAAvB,EAA+B;AAAE,MAAA,MAAM,GAAG,IAAI,CAAC,KAAL,EAAT;AAAwB;;AAEzD,QAAI,MAAM,GAAG,UAAU,CAAiB,WAAjB,EAA8B,IAA9B,CAAvB;;AAEA,QAAI,CAAC,MAAD,IAAW,EAAE,MAAM,GAAG,MAAM,CAAC,CAAD,CAAN,IAAa,MAAM,CAAC,CAAD,CAAN,CAAU,MAAlC,CAAf,EAA0D;AACtD,YAAM,IAAI,SAAJ,CAAc,qEAAd,CAAN;AACH;;AAED,IAAA,MAAM,CAAC,CAAD,CAAN,KAAc,MAAM,CAAC,CAAD,CAAN,GAAY,IAAI,oCAAJ,CAAyC,MAAzC,CAA1B;AAEA,UAAM,IAAI,MAAJ,CAAW,MAAM,CAAC,MAAlB,CAAN,EAAiC,MAAjC;AAEA,SAAK,OAAL,GAAe,MAAf;AACA,SAAK,OAAL,GAAe,MAAf;AACH;AA1ID;;;AACO,SAAO,KAAP,CAAyD,MAAA,GAAS,IAAI,MAAJ,CAAc,EAAd,CAAlE,EAAmF;AAAI,WAAO,IAAI,KAAJ,CAAa,MAAb,EAAqB,EAArB,CAAP;AAAkC;AAahI;;;AACO,SAAO,IAAP,CAAsE,KAAtE,EAAiF;AAEpF,QAAI,CAAC,KAAL,EAAY;AAAE,aAAO,KAAK,CAAC,KAAN,EAAP;AAAuB;;AAErC,QAAI,OAAO,KAAP,KAAiB,QAArB,EAA+B;AAC3B,UAAI,KAAK,GAAG,UAAU,CAAC,KAAK,CAAC,QAAD,CAAN,CAAV,GAA8B,iBAAiB,CAAW,KAAX,CAA/C,GACL,eAAe,CAAC,KAAK,CAAC,QAAD,CAAN,CAAf,GAAmC,sBAAsB,CAAW,KAAX,CAAzD,GACmC,IAF1C;;AAGA,UAAI,KAAK,KAAK,IAAd,EAAoB;AAAE,eAAO,KAAP;AAAe;AACxC;;AAED,QAAI,MAAM,GAAG,iBAAiB,CAAC,IAAlB,CAA0B,KAA1B,CAAb;;AAEA,QAAI,SAAS,CAAuB,MAAvB,CAAb,EAA6C;AACzC,aAAO,CAAC,YAAY,MAAM,KAAK,CAAC,IAAN,EAAW,MAAM,MAAjB,EAAnB,GAAP;AACH;;AACD,QAAI,MAAM,CAAC,MAAP,OAAoB,MAAM,GAAG,MAAM,CAAC,IAAP,EAA7B,CAAJ,EAAiD;AAC7C,aAAO,CAAC,MAAM,CAAC,MAAR,GAAiB,KAAK,CAAC,KAAN,EAAjB,GAAiC,IAAI,KAAJ,CAAa,MAAM,CAAC,MAApB,EAA4B,CAAC,GAAG,MAAJ,CAA5B,CAAxC;AACH;;AACD,WAAO,CAAC,MAAO,OAAP,IAAkB;AACtB,YAAM,MAAM,GAAG,MAAM,OAArB;AACA,YAAM,MAAM,GAAG,MAAM,CAAC,MAAtB;AACA,YAAM,OAAO,GAAkB,EAA/B;;AACA,UAAI,MAAJ,EAAY;AACR,mBAAW,IAAI,KAAf,IAAwB,MAAxB,EAAgC;AAC5B,UAAA,OAAO,CAAC,IAAR,CAAa,KAAb;AACH;;AACD,eAAO,IAAI,KAAJ,CAAa,MAAb,EAAqB,OAArB,CAAP;AACH;;AACD,aAAO,KAAK,CAAC,KAAN,EAAP;AACH,KAXM,EAWJ,MAAM,CAAC,IAAP,EAXI,CAAP;AAYH;AAED;;;AACO,eAAa,SAAb,CAAoE,MAApE,EAA2G;AAC9G,WAAO,MAAM,KAAK,CAAC,IAAN,CAAc,MAAd,CAAb;AACH;AAED;;;AACO,SAAO,UAAP,CAA+D,MAA/D,EAAwF;AAC3F,WAAO,KAAK,CAAC,GAAN,CAAa,MAAM,CAAC,IAAP,CAAY,SAAzB,EAA0D,MAAM,CAAC,IAAP,CAAY,QAAtE,CAAP;AACH;AAuDD;;;AACO,SAAO,GAAP,CAAW,GAAG,IAAd,EAAyB;AAC5B,WAAO,IAAI,KAAJ,CAAU,GAAG,kCAAkC,CAAC,gBAAgB,CAAC,IAAD,CAAjB,CAA/C,CAAP;AACH;;AA+BD,MAAW,MAAX,GAAiB;AAAK,WAAO,KAAK,OAAZ;AAAsB;;AAC5C,MAAW,MAAX,GAAiB;AAAK,WAAO,KAAK,OAAZ;AAAsB;;AAC5C,MAAW,MAAX,GAAiB;AAAK,WAAO,KAAK,OAAZ;AAAsB;;AAC5C,MAAW,OAAX,GAAkB;AAAK,WAAO,KAAK,YAAZ;AAA2B;;AAE3C,EAAA,KAAK,CAAC,MAAM,GAAG,KAAK,OAAf,EAAsB;AAC9B,WAAO,IAAI,KAAJ,CAAa,KAAK,OAAlB,EAA2B,MAA3B,CAAP;AACH;;AAEM,EAAA,SAAS,CAAoB,IAApB,EAA2B;AACvC,WAAO,KAAK,WAAL,CAAiB,KAAK,cAAL,CAAoB,IAApB,CAAjB,CAAP;AACH;;AACM,EAAA,WAAW,CAA2B,KAA3B,EAAwC;AACtD,WAAO,KAAK,UAAL,CAAgB,KAAhB,CAAP;AACH;;AACM,EAAA,cAAc,CAAoB,IAApB,EAA2B;AAC5C,WAAO,KAAK,OAAL,CAAa,MAAb,CAAoB,SAApB,CAA+B,CAAD,IAAO,CAAC,CAAC,IAAF,KAAW,IAAhD,CAAP;AACH;;AACM,EAAA,UAAU,CAA2B,KAA3B,EAAwC;AACrD,QAAI,KAAK,GAAG,CAAR,IAAa,KAAK,IAAI,KAAK,WAA/B,EAA4C;AAAE,aAAO,IAAP;AAAc;;AAC5D,QAAI,KAAJ,EAAqB,KAArB;AACA,UAAM,MAAM,GAAI,KAAK,OAAL,CAA6B,MAA7C;AACA,UAAM,OAAO,GAAG,KAAK,SAAL,KAAmB,KAAK,SAAL,GAAiB,EAApC,CAAhB;;AACA,QAAI,KAAK,GAAG,OAAO,CAAC,KAAD,CAAnB,EAA4B;AAAE,aAAO,KAAP;AAA4B;;AAC1D,QAAI,KAAK,GAAG,MAAM,CAAC,KAAD,CAAlB,EAA2B;AACvB,YAAM,MAAM,GAAG,KAAK,OAAL,CACV,GADU,CACL,KAAD,IAAW,KAAK,CAAC,UAAN,CAAoB,KAApB,CADL,EAEV,MAFU,CAEF,GAAD,IAA2B,GAAG,IAAI,IAF/B,CAAf;;AAGA,UAAI,MAAM,CAAC,MAAP,GAAgB,CAApB,EAAuB;AACnB,eAAQ,OAAO,CAAC,KAAD,CAAP,GAAiB,IAAI,MAAJ,CAAc,KAAd,EAAqB,MAArB,CAAzB;AACH;AACJ;;AACD,WAAO,IAAP;AACH,GAxLyB,CA0L1B;;;AACO,EAAA,SAAS,CAAC,QAAQ,GAAG,QAAZ,EAAsB,MAAM,GAAG,IAA/B,EAAmC;AAC/C,UAAM,MAAM,GAAG,CAAC,MAAD,GACT,qBADS,GAET,uBAFN;AAGA,WAAO,MAAM,CAAC,QAAP,CAAgB,IAAhB,EAAsB,YAAtB,CAAmC,IAAnC,CAAP;AACH;;AACM,EAAA,KAAK,GAAA;AACR,WAAO,KAAK,OAAZ;AACH;;AACM,EAAA,MAAM,CAA0B,GAAG,WAA7B,EAA6C;AACtD,UAAM,WAAW,GAAG,KAAK,OAAL,CAAa,MAAb,CAAoB,MAApB,CAA2B,CAAC,CAAD,EAAI,CAAJ,EAAO,CAAP,KAAa,CAAC,CAAC,GAAF,CAAM,CAAC,CAAC,IAAR,EAAmB,CAAnB,CAAxC,EAA+D,IAAI,GAAJ,EAA/D,CAApB;;AACA,WAAO,KAAK,QAAL,CAAc,GAAG,WAAW,CAAC,GAAZ,CAAiB,UAAD,IAAgB,WAAW,CAAC,GAAZ,CAAgB,UAAhB,CAAhC,EAA8D,MAA9D,CAAsE,CAAD,IAAO,CAAC,GAAG,CAAC,CAAjF,CAAjB,CAAP;AACH;;AACM,EAAA,QAAQ,CAA6B,GAAG,aAAhC,EAAuD;AAClE,UAAM,MAAM,GAAG,KAAK,OAAL,CAAa,QAAb,CAAyB,GAAG,aAA5B,CAAf;;AACA,WAAO,IAAI,KAAJ,CAAU,MAAV,EAAkB,KAAK,OAAL,CAAa,GAAb,CAAiB,CAAC;AAAE,MAAA,MAAF;AAAU,MAAA,IAAI,EAAE;AAAE,QAAA;AAAF;AAAhB,KAAD,KAAoC;AAC1E,aAAO,IAAI,WAAJ,CAAgB,MAAhB,EAAwB,MAAxB,EAAgC,aAAa,CAAC,GAAd,CAAmB,CAAD,IAAO,SAAS,CAAC,CAAD,CAAlC,EAAuC,MAAvC,CAA8C,OAA9C,CAAhC,CAAP;AACH,KAFwB,CAAlB,CAAP;AAGH;;AACM,EAAA,MAAM,CAA8C,KAA9C,EAA6D;AAEtE,UAAM,MAAM,GAAG,KAAK,OAAL,CAAa,MAA5B;AACA,UAAM,CAAC,OAAD,EAAU,QAAV,IAAsB,KAAK,CAAC,MAAN,CAAa,MAAb,CAAoB,MAApB,CAA2B,CAAC,IAAD,EAAO,EAAP,EAAW,MAAX,KAAqB;AACxE,YAAM,CAAC,OAAD,EAAU,QAAV,IAAsB,IAA5B;AACA,YAAM,CAAC,GAAG,MAAM,CAAC,SAAP,CAAkB,CAAD,IAAO,CAAC,CAAC,IAAF,KAAW,EAAE,CAAC,IAAtC,CAAV;AACA,OAAC,CAAD,GAAM,QAAQ,CAAC,CAAD,CAAR,GAAc,MAApB,GAA8B,OAAO,CAAC,IAAR,CAAa,MAAb,CAA9B;AACA,aAAO,IAAP;AACH,KAL2B,EAKzB,CAAC,EAAD,EAAK,EAAL,CALyB,CAA5B;;AAOA,UAAM,MAAM,GAAG,KAAK,OAAL,CAAa,MAAb,CAAoB,KAAK,CAAC,MAA1B,CAAf;;AACA,UAAM,OAAO,GAAG,CACZ,GAAG,MAAM,CAAC,GAAP,CAAW,CAAC,EAAD,EAAK,CAAL,EAAQ,GAAR,EAAa,CAAC,GAAG,QAAQ,CAAC,CAAD,CAAzB,KACT,CAAC,KAAK,SAAN,GAAkB,KAAK,WAAL,CAAiB,CAAjB,CAAlB,GAAwC,KAAK,CAAC,WAAN,CAAkB,CAAlB,CAD1C,CADS,EAGZ,GAAG,OAAO,CAAC,GAAR,CAAa,CAAD,IAAO,KAAK,CAAC,WAAN,CAAkB,CAAlB,CAAnB,CAHS,EAId,MAJc,CAIP,OAJO,CAAhB;AAMA,WAAO,IAAI,KAAJ,CAAiB,GAAG,kCAAkC,CAAM,MAAN,EAAc,OAAd,CAAtD,CAAP;AACH;;AAhOyB;;AAmO9B,SAAS,iBAAT,CAAqF,KAArF,EAAkI;AAC9H,QAAM;AAAE,IAAA;AAAF,MAAW,KAAjB;;AACA,MAAI,IAAI,YAAY,MAApB,EAA4B;AACxB,WAAO,KAAK,CAAC,UAAN,CAAiB,YAAY,CAAC,IAAb,CAAkB,KAAlB,CAAjB,CAAP;AACH;;AACD,SAAO,IAAP;AACH;;AAED,SAAS,sBAAT,CAA0F,KAA1F,EAA4I;AACxI,QAAM;AAAE,IAAA;AAAF,MAAW,KAAjB;;AACA,MAAI,IAAI,YAAY,MAApB,EAA4B;AACxB,WAAO,YAAY,CAAC,IAAb,CAAkB,KAAlB,EAAwE,IAAxE,CAA8E,MAAD,IAAY,KAAK,CAAC,UAAN,CAAiB,MAAjB,CAAzF,CAAP;AACH;;AACD,SAAO,IAAP;AACH","sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Data } from './data';\nimport { Column } from './column';\nimport { Schema, Field } from './schema';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from './recordbatch';\nimport { DataFrame } from './compute/dataframe';\nimport { RecordBatchReader } from './ipc/reader';\nimport { DataType, RowLike, Struct } from './type';\nimport { selectColumnArgs, selectArgs } from './util/args';\nimport { Clonable, Sliceable, Applicative } from './vector';\nimport { isPromise, isIterable, isAsyncIterable } from './util/compat';\nimport { RecordBatchFileWriter, RecordBatchStreamWriter } from './ipc/writer';\nimport { distributeColumnsIntoRecordBatches, distributeVectorsIntoRecordBatches } from './util/recordbatch';\nimport { Vector, Chunked, StructVector, VectorBuilderOptions, VectorBuilderOptionsAsync } from './vector/index';\n\ntype VectorMap = { [key: string]: Vector };\ntype Fields<T extends { [key: string]: DataType }> = (keyof T)[] | Field<T[keyof T]>[];\ntype ChildData<T extends { [key: string]: DataType }> = Data<T[keyof T]>[] | Vector<T[keyof T]>[];\ntype Columns<T extends { [key: string]: DataType }> = Column<T[keyof T]>[] | Column<T[keyof T]>[][];\n\nexport interface Table<T extends { [key: string]: DataType } = any> {\n\n    get(index: number): Struct<T>['TValue'];\n    [Symbol.iterator](): IterableIterator<RowLike<T>>;\n\n    slice(begin?: number, end?: number): Table<T>;\n    concat(...others: Vector<Struct<T>>[]): Table<T>;\n    clone(chunks?: RecordBatch<T>[], offsets?: Uint32Array): Table<T>;\n\n    scan(next: import('./compute/dataframe').NextFunc, bind?: import('./compute/dataframe').BindFunc): void;\n    scanReverse(next: import('./compute/dataframe').NextFunc, bind?: import('./compute/dataframe').BindFunc): void;\n    countBy(name: import('./compute/predicate').Col | string): import('./compute/dataframe').CountByResult;\n    filter(predicate: import('./compute/predicate').Predicate): import('./compute/dataframe').FilteredDataFrame<T>;\n}\n\nexport class Table<T extends { [key: string]: DataType } = any>\n    extends Chunked<Struct<T>>\n    implements DataFrame<T>,\n               Clonable<Table<T>>,\n               Sliceable<Table<T>>,\n               Applicative<Struct<T>, Table<T>> {\n\n    /** @nocollapse */\n    public static empty<T extends { [key: string]: DataType } = {}>(schema = new Schema<T>([])) { return new Table<T>(schema, []); }\n\n    public static from(): Table<{}>;\n    public static from<T extends { [key: string]: DataType } = any>(source: RecordBatchReader<T>): Table<T>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg0): Table<T>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg2): Table<T>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg1): Promise<Table<T>>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg3): Promise<Table<T>>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg4): Promise<Table<T>>;\n    public static from<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArg5): Promise<Table<T>>;\n    public static from<T extends { [key: string]: DataType } = any>(source: PromiseLike<RecordBatchReader<T>>): Promise<Table<T>>;\n    public static from<T extends { [key: string]: DataType } = any, TNull = any>(options: VectorBuilderOptions<Struct<T>, TNull>): Table<T>;\n    public static from<T extends { [key: string]: DataType } = any, TNull = any>(options: VectorBuilderOptionsAsync<Struct<T>, TNull>): Promise<Table<T>>;\n    /** @nocollapse */\n    public static from<T extends { [key: string]: DataType } = any, TNull = any>(input?: any) {\n\n        if (!input) { return Table.empty(); }\n\n        if (typeof input === 'object') {\n            let table = isIterable(input['values']) ? tableFromIterable<T, TNull>(input)\n                 : isAsyncIterable(input['values']) ? tableFromAsyncIterable<T, TNull>(input)\n                                                    : null;\n            if (table !== null) { return table; }\n        }\n\n        let reader = RecordBatchReader.from<T>(input) as RecordBatchReader<T> | Promise<RecordBatchReader<T>>;\n\n        if (isPromise<RecordBatchReader<T>>(reader)) {\n            return (async () => await Table.from(await reader))();\n        }\n        if (reader.isSync() && (reader = reader.open())) {\n            return !reader.schema ? Table.empty() : new Table<T>(reader.schema, [...reader]);\n        }\n        return (async (opening) => {\n            const reader = await opening;\n            const schema = reader.schema;\n            const batches: RecordBatch[] = [];\n            if (schema) {\n                for await (let batch of reader) {\n                    batches.push(batch);\n                }\n                return new Table<T>(schema, batches);\n            }\n            return Table.empty();\n        })(reader.open());\n    }\n\n    /** @nocollapse */\n    public static async fromAsync<T extends { [key: string]: DataType } = any>(source: import('./ipc/reader').FromArgs): Promise<Table<T>> {\n        return await Table.from<T>(source as any);\n    }\n\n    /** @nocollapse */\n    public static fromStruct<T extends { [key: string]: DataType } = any>(vector: Vector<Struct<T>>) {\n        return Table.new<T>(vector.data.childData as Data<T[keyof T]>[], vector.type.children);\n    }\n\n    /**\n     * @summary Create a new Table from a collection of Columns or Vectors,\n     * with an optional list of names or Fields.\n     *\n     *\n     * `Table.new` accepts an Object of\n     * Columns or Vectors, where the keys will be used as the field names\n     * for the Schema:\n     * ```ts\n     * const i32s = Int32Vector.from([1, 2, 3]);\n     * const f32s = Float32Vector.from([.1, .2, .3]);\n     * const table = Table.new({ i32: i32s, f32: f32s });\n     * assert(table.schema.fields[0].name === 'i32');\n     * ```\n     *\n     * It also accepts a a list of Vectors with an optional list of names or\n     * Fields for the resulting Schema. If the list is omitted or a name is\n     * missing, the numeric index of each Vector will be used as the name:\n     * ```ts\n     * const i32s = Int32Vector.from([1, 2, 3]);\n     * const f32s = Float32Vector.from([.1, .2, .3]);\n     * const table = Table.new([i32s, f32s], ['i32']);\n     * assert(table.schema.fields[0].name === 'i32');\n     * assert(table.schema.fields[1].name === '1');\n     * ```\n     *\n     * If the supplied arguments are Columns, `Table.new` will infer the Schema\n     * from the Columns:\n     * ```ts\n     * const i32s = Column.new('i32', Int32Vector.from([1, 2, 3]));\n     * const f32s = Column.new('f32', Float32Vector.from([.1, .2, .3]));\n     * const table = Table.new(i32s, f32s);\n     * assert(table.schema.fields[0].name === 'i32');\n     * assert(table.schema.fields[1].name === 'f32');\n     * ```\n     *\n     * If the supplied Vector or Column lengths are unequal, `Table.new` will\n     * extend the lengths of the shorter Columns, allocating additional bytes\n     * to represent the additional null slots. The memory required to allocate\n     * these additional bitmaps can be computed as:\n     * ```ts\n     * let additionalBytes = 0;\n     * for (let vec in shorter_vectors) {\n     *     additionalBytes += (((longestLength - vec.length) + 63) & ~63) >> 3;\n     * }\n     * ```\n     *\n     * For example, an additional null bitmap for one million null values would require\n     * 125,000 bytes (`((1e6 + 63) & ~63) >> 3`), or approx. `0.11MiB`\n     */\n    public static new<T extends { [key: string]: DataType } = any>(...columns: Columns<T>): Table<T>;\n    public static new<T extends VectorMap = any>(children: T): Table<{ [P in keyof T]: T[P]['type'] }>;\n    public static new<T extends { [key: string]: DataType } = any>(children: ChildData<T>, fields?: Fields<T>): Table<T>;\n    /** @nocollapse */\n    public static new(...cols: any[]) {\n        return new Table(...distributeColumnsIntoRecordBatches(selectColumnArgs(cols)));\n    }\n\n    constructor(batches: RecordBatch<T>[]);\n    constructor(...batches: RecordBatch<T>[]);\n    constructor(schema: Schema<T>, batches: RecordBatch<T>[]);\n    constructor(schema: Schema<T>, ...batches: RecordBatch<T>[]);\n    constructor(...args: any[]) {\n\n        let schema: Schema<T> = null!;\n\n        if (args[0] instanceof Schema) { schema = args.shift(); }\n\n        let chunks = selectArgs<RecordBatch<T>>(RecordBatch, args);\n\n        if (!schema && !(schema = chunks[0] && chunks[0].schema)) {\n            throw new TypeError('Table must be initialized with a Schema or at least one RecordBatch');\n        }\n\n        chunks[0] || (chunks[0] = new _InternalEmptyPlaceholderRecordBatch(schema));\n\n        super(new Struct(schema.fields), chunks);\n\n        this._schema = schema;\n        this._chunks = chunks;\n    }\n\n    protected _schema: Schema<T>;\n    // List of inner RecordBatches\n    protected _chunks: RecordBatch<T>[];\n    protected _children?: Column<T[keyof T]>[];\n\n    public get schema() { return this._schema; }\n    public get length() { return this._length; }\n    public get chunks() { return this._chunks; }\n    public get numCols() { return this._numChildren; }\n\n    public clone(chunks = this._chunks) {\n        return new Table<T>(this._schema, chunks);\n    }\n\n    public getColumn<R extends keyof T>(name: R): Column<T[R]> {\n        return this.getColumnAt(this.getColumnIndex(name)) as Column<T[R]>;\n    }\n    public getColumnAt<R extends DataType = any>(index: number): Column<R> | null {\n        return this.getChildAt(index);\n    }\n    public getColumnIndex<R extends keyof T>(name: R) {\n        return this._schema.fields.findIndex((f) => f.name === name);\n    }\n    public getChildAt<R extends DataType = any>(index: number): Column<R> | null {\n        if (index < 0 || index >= this.numChildren) { return null; }\n        let field: Field<R>, child: Column<R>;\n        const fields = (this._schema as Schema<any>).fields;\n        const columns = this._children || (this._children = []) as Column[];\n        if (child = columns[index]) { return child as Column<R>; }\n        if (field = fields[index]) {\n            const chunks = this._chunks\n                .map((chunk) => chunk.getChildAt<R>(index))\n                .filter((vec): vec is Vector<R> => vec != null);\n            if (chunks.length > 0) {\n                return (columns[index] = new Column<R>(field, chunks));\n            }\n        }\n        return null;\n    }\n\n    // @ts-ignore\n    public serialize(encoding = 'binary', stream = true) {\n        const Writer = !stream\n            ? RecordBatchFileWriter\n            : RecordBatchStreamWriter;\n        return Writer.writeAll(this).toUint8Array(true);\n    }\n    public count(): number {\n        return this._length;\n    }\n    public select<K extends keyof T = any>(...columnNames: K[]) {\n        const nameToIndex = this._schema.fields.reduce((m, f, i) => m.set(f.name as K, i), new Map<K, number>());\n        return this.selectAt(...columnNames.map((columnName) => nameToIndex.get(columnName)!).filter((x) => x > -1));\n    }\n    public selectAt<K extends T[keyof T] = any>(...columnIndices: number[]) {\n        const schema = this._schema.selectAt<K>(...columnIndices);\n        return new Table(schema, this._chunks.map(({ length, data: { childData } }) => {\n            return new RecordBatch(schema, length, columnIndices.map((i) => childData[i]).filter(Boolean));\n        }));\n    }\n    public assign<R extends { [key: string]: DataType } = any>(other: Table<R>) {\n\n        const fields = this._schema.fields;\n        const [indices, oldToNew] = other.schema.fields.reduce((memo, f2, newIdx) => {\n            const [indices, oldToNew] = memo;\n            const i = fields.findIndex((f) => f.name === f2.name);\n            ~i ? (oldToNew[i] = newIdx) : indices.push(newIdx);\n            return memo;\n        }, [[], []] as number[][]);\n\n        const schema = this._schema.assign(other.schema);\n        const columns = [\n            ...fields.map((_f, i, _fs, j = oldToNew[i]) =>\n                (j === undefined ? this.getColumnAt(i) : other.getColumnAt(j))!),\n            ...indices.map((i) => other.getColumnAt(i)!)\n        ].filter(Boolean) as Column<(T & R)[keyof T | keyof R]>[];\n\n        return new Table<T & R>(...distributeVectorsIntoRecordBatches<any>(schema, columns));\n    }\n}\n\nfunction tableFromIterable<T extends { [key: string]: DataType } = any, TNull = any>(input: VectorBuilderOptions<Struct<T>, TNull>) {\n    const { type } = input;\n    if (type instanceof Struct) {\n        return Table.fromStruct(StructVector.from(input as VectorBuilderOptions<Struct<T>, TNull>));\n    }\n    return null;\n}\n\nfunction tableFromAsyncIterable<T extends { [key: string]: DataType } = any, TNull = any>(input: VectorBuilderOptionsAsync<Struct<T>, TNull>) {\n    const { type } = input;\n    if (type instanceof Struct) {\n        return StructVector.from(input as VectorBuilderOptionsAsync<Struct<T>, TNull>).then((vector) => Table.fromStruct(vector));\n    }\n    return null;\n}\n"]},"metadata":{},"sourceType":"module"}