{"ast":null,"code":"import _construct from \"/home/lsb/wikidatageo/dark-sky-vacations/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/construct\";\nimport _slicedToArray from \"/home/lsb/wikidatageo/dark-sky-vacations/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\nimport _toConsumableArray from \"/home/lsb/wikidatageo/dark-sky-vacations/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/toConsumableArray\";\nimport _classCallCheck from \"/home/lsb/wikidatageo/dark-sky-vacations/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/home/lsb/wikidatageo/dark-sky-vacations/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _createSuper from \"/home/lsb/wikidatageo/dark-sky-vacations/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createSuper\";\nimport _inherits from \"/home/lsb/wikidatageo/dark-sky-vacations/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { Data } from './data';\nimport { Table } from './table';\nimport { Vector } from './vector';\nimport { Visitor } from './visitor';\nimport { Schema } from './schema';\nimport { isIterable } from './util/compat';\nimport { Chunked } from './vector/chunked';\nimport { selectFieldArgs } from './util/args';\nimport { DataType, Struct } from './type';\nimport { ensureSameLengthData } from './util/recordbatch';\nimport { StructVector } from './vector/index';\nexport var RecordBatch = /*#__PURE__*/function (_StructVector) {\n  _inherits(RecordBatch, _StructVector);\n\n  var _super = _createSuper(RecordBatch);\n\n  function RecordBatch() {\n    var _this;\n\n    _classCallCheck(this, RecordBatch);\n\n    var data;\n\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n\n    var schema = args[0];\n    var children;\n\n    if (args[1] instanceof Data) {\n      data = args[1];\n      children = args[2];\n    } else {\n      var fields = schema.fields;\n      var length = args[1],\n          childData = args[2];\n      data = Data.Struct(new Struct(fields), 0, length, 0, null, childData);\n    }\n\n    _this = _super.call(this, data, children);\n    _this._schema = schema;\n    return _this;\n  }\n  /** @nocollapse */\n\n\n  _createClass(RecordBatch, [{\n    key: \"clone\",\n    value: function clone(data) {\n      var children = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : this._children;\n      return new RecordBatch(this._schema, data, children);\n    }\n  }, {\n    key: \"concat\",\n    value: function concat() {\n      for (var _len2 = arguments.length, others = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {\n        others[_key2] = arguments[_key2];\n      }\n\n      var schema = this._schema,\n          chunks = Chunked.flatten.apply(Chunked, [this].concat(others));\n      return new Table(schema, chunks.map(function (_ref) {\n        var data = _ref.data;\n        return new RecordBatch(schema, data);\n      }));\n    }\n  }, {\n    key: \"select\",\n    value: function select() {\n      var nameToIndex = this._schema.fields.reduce(function (m, f, i) {\n        return m.set(f.name, i);\n      }, new Map());\n\n      for (var _len3 = arguments.length, columnNames = new Array(_len3), _key3 = 0; _key3 < _len3; _key3++) {\n        columnNames[_key3] = arguments[_key3];\n      }\n\n      return this.selectAt.apply(this, _toConsumableArray(columnNames.map(function (columnName) {\n        return nameToIndex.get(columnName);\n      }).filter(function (x) {\n        return x > -1;\n      })));\n    }\n  }, {\n    key: \"selectAt\",\n    value: function selectAt() {\n      var _this$_schema,\n          _this2 = this;\n\n      for (var _len4 = arguments.length, columnIndices = new Array(_len4), _key4 = 0; _key4 < _len4; _key4++) {\n        columnIndices[_key4] = arguments[_key4];\n      }\n\n      var schema = (_this$_schema = this._schema).selectAt.apply(_this$_schema, columnIndices);\n\n      var childData = columnIndices.map(function (i) {\n        return _this2.data.childData[i];\n      }).filter(Boolean);\n      return new RecordBatch(schema, this.length, childData);\n    }\n  }, {\n    key: \"schema\",\n    get: function get() {\n      return this._schema;\n    }\n  }, {\n    key: \"numCols\",\n    get: function get() {\n      return this._schema.fields.length;\n    }\n  }, {\n    key: \"dictionaries\",\n    get: function get() {\n      return this._dictionaries || (this._dictionaries = DictionaryCollector.collect(this));\n    }\n  }], [{\n    key: \"from\",\n    value: function from(options) {\n      if (isIterable(options['values'])) {\n        return Table.from(options);\n      }\n\n      return Table.from(options);\n    }\n    /** @nocollapse */\n\n  }, {\n    key: \"new\",\n    value: function _new() {\n      for (var _len5 = arguments.length, args = new Array(_len5), _key5 = 0; _key5 < _len5; _key5++) {\n        args[_key5] = arguments[_key5];\n      }\n\n      var _selectFieldArgs = selectFieldArgs(args),\n          _selectFieldArgs2 = _slicedToArray(_selectFieldArgs, 2),\n          fs = _selectFieldArgs2[0],\n          xs = _selectFieldArgs2[1];\n\n      var vs = xs.filter(function (x) {\n        return x instanceof Vector;\n      });\n      return _construct(RecordBatch, _toConsumableArray(ensureSameLengthData(new Schema(fs), vs.map(function (x) {\n        return x.data;\n      }))));\n    }\n  }]);\n\n  return RecordBatch;\n}(StructVector);\n/**\n * An internal class used by the `RecordBatchReader` and `RecordBatchWriter`\n * implementations to differentiate between a stream with valid zero-length\n * RecordBatches, and a stream with a Schema message, but no RecordBatches.\n * @see https://github.com/apache/arrow/pull/4373\n * @ignore\n * @private\n */\n\n/* tslint:disable:class-name */\n\nexport var _InternalEmptyPlaceholderRecordBatch = /*#__PURE__*/function (_RecordBatch) {\n  _inherits(_InternalEmptyPlaceholderRecordBatch, _RecordBatch);\n\n  var _super2 = _createSuper(_InternalEmptyPlaceholderRecordBatch);\n\n  function _InternalEmptyPlaceholderRecordBatch(schema) {\n    _classCallCheck(this, _InternalEmptyPlaceholderRecordBatch);\n\n    return _super2.call(this, schema, 0, schema.fields.map(function (f) {\n      return Data.new(f.type, 0, 0, 0);\n    }));\n  }\n\n  return _InternalEmptyPlaceholderRecordBatch;\n}(RecordBatch);\n/** @ignore */\n\nvar DictionaryCollector = /*#__PURE__*/function (_Visitor) {\n  _inherits(DictionaryCollector, _Visitor);\n\n  var _super3 = _createSuper(DictionaryCollector);\n\n  function DictionaryCollector() {\n    var _this3;\n\n    _classCallCheck(this, DictionaryCollector);\n\n    _this3 = _super3.apply(this, arguments);\n    _this3.dictionaries = new Map();\n    return _this3;\n  }\n\n  _createClass(DictionaryCollector, [{\n    key: \"visit\",\n    value: function visit(data, type) {\n      var _this4 = this;\n\n      if (DataType.isDictionary(type)) {\n        return this.visitDictionary(data, type);\n      } else {\n        data.childData.forEach(function (child, i) {\n          return _this4.visit(child, type.children[i].type);\n        });\n      }\n\n      return this;\n    }\n  }, {\n    key: \"visitDictionary\",\n    value: function visitDictionary(data, type) {\n      var dictionary = data.dictionary;\n\n      if (dictionary && dictionary.length > 0) {\n        this.dictionaries.set(type.id, dictionary);\n      }\n\n      return this;\n    }\n  }], [{\n    key: \"collect\",\n    value: function collect(batch) {\n      return new DictionaryCollector().visit(batch.data, new Struct(batch.schema.fields)).dictionaries;\n    }\n  }]);\n\n  return DictionaryCollector;\n}(Visitor);","map":{"version":3,"sources":["recordbatch.ts"],"names":[],"mappings":";;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SAAS,IAAT,QAAqB,QAArB;AACA,SAAS,KAAT,QAAsB,SAAtB;AACA,SAAS,MAAT,QAAuB,UAAvB;AACA,SAAS,OAAT,QAAwB,WAAxB;AACA,SAAS,MAAT,QAA8B,UAA9B;AACA,SAAS,UAAT,QAA2B,eAA3B;AACA,SAAS,OAAT,QAAwB,kBAAxB;AACA,SAAS,eAAT,QAAgC,aAAhC;AACA,SAAS,QAAT,EAAmB,MAAnB,QAA6C,QAA7C;AACA,SAAS,oBAAT,QAAqC,oBAArC;AAEA,SAAS,YAAT,QAA8E,gBAA9E;AAYA,WAAa,WAAb;AAAA;;AAAA;;AA8BI,yBAA0B;AAAA;;AAAA;;AACtB,QAAI,IAAJ;;AADsB,sCAAX,IAAW;AAAX,MAAA,IAAW;AAAA;;AAEtB,QAAI,MAAM,GAAG,IAAI,CAAC,CAAD,CAAjB;AACA,QAAI,QAAJ;;AACA,QAAI,IAAI,CAAC,CAAD,CAAJ,YAAmB,IAAvB,EAA6B;AACtB,MAAA,IADsB,GACH,IADG;AAChB,MAAA,QADgB,GACH,IADG;AAE5B,KAFD,MAEO;AACH,UAAM,MAAM,GAAG,MAAM,CAAC,MAAtB;AADG,UAEM,MAFN,GAE2B,IAF3B;AAAA,UAEc,SAFd,GAE2B,IAF3B;AAGH,MAAA,IAAI,GAAG,IAAI,CAAC,MAAL,CAAY,IAAI,MAAJ,CAAc,MAAd,CAAZ,EAAmC,CAAnC,EAAsC,MAAtC,EAA8C,CAA9C,EAAiD,IAAjD,EAAuD,SAAvD,CAAP;AACH;;AACD,8BAAM,IAAN,EAAY,QAAZ;AACA,UAAK,OAAL,GAAe,MAAf;AAZsB;AAazB;AAnCD;;;AARJ;AAAA;AAAA,0BA6CiB,IA7CjB,EA6CiE;AAAA,UAAzB,QAAyB,uEAAd,KAAK,SAAS;AACzD,aAAO,IAAI,WAAJ,CAAmB,KAAK,OAAxB,EAAiC,IAAjC,EAAuC,QAAvC,CAAP;AACH;AA/CL;AAAA;AAAA,6BAiDgD;AAAA,yCAA3B,MAA2B;AAA3B,QAAA,MAA2B;AAAA;;AACxC,UAAM,MAAM,GAAG,KAAK,OAApB;AAAA,UAA6B,MAAM,GAAG,OAAO,CAAC,OAAR,OAAA,OAAO,GAAS,IAAT,SAAkB,MAAlB,EAA7C;AACA,aAAO,IAAI,KAAJ,CAAU,MAAV,EAAkB,MAAM,CAAC,GAAP,CAAW;AAAA,YAAG,IAAH,QAAG,IAAH;AAAA,eAAc,IAAI,WAAJ,CAAgB,MAAhB,EAAwB,IAAxB,CAAd;AAAA,OAAX,CAAlB,CAAP;AACH;AApDL;AAAA;AAAA,6BA4D8D;AACtD,UAAM,WAAW,GAAG,KAAK,OAAL,CAAa,MAAb,CAAoB,MAApB,CAA2B,UAAC,CAAD,EAAI,CAAJ,EAAO,CAAP;AAAA,eAAa,CAAC,CAAC,GAAF,CAAM,CAAC,CAAC,IAAR,EAAmB,CAAnB,CAAb;AAAA,OAA3B,EAA+D,IAAI,GAAJ,EAA/D,CAApB;;AADsD,yCAAhB,WAAgB;AAAhB,QAAA,WAAgB;AAAA;;AAEtD,aAAO,KAAK,QAAL,gCAAiB,WAAW,CAAC,GAAZ,CAAgB,UAAC,UAAD;AAAA,eAAgB,WAAW,CAAC,GAAZ,CAAgB,UAAhB,CAAhB;AAAA,OAAhB,EAA8D,MAA9D,CAAqE,UAAC,CAAD;AAAA,eAAO,CAAC,GAAG,CAAC,CAAZ;AAAA,OAArE,CAAjB,EAAP;AACH;AA/DL;AAAA;AAAA,+BAgE0E;AAAA;AAAA;;AAAA,yCAAvB,aAAuB;AAAvB,QAAA,aAAuB;AAAA;;AAClE,UAAM,MAAM,GAAG,sBAAK,OAAL,EAAa,QAAb,sBAAyB,aAAzB,CAAf;;AACA,UAAM,SAAS,GAAG,aAAa,CAAC,GAAd,CAAkB,UAAC,CAAD;AAAA,eAAO,MAAI,CAAC,IAAL,CAAU,SAAV,CAAoB,CAApB,CAAP;AAAA,OAAlB,EAAiD,MAAjD,CAAwD,OAAxD,CAAlB;AACA,aAAO,IAAI,WAAJ,CAAsC,MAAtC,EAA8C,KAAK,MAAnD,EAA2D,SAA3D,CAAP;AACH;AApEL;AAAA;AAAA,wBAsDqB;AAAK,aAAO,KAAK,OAAZ;AAAsB;AAtDhD;AAAA;AAAA,wBAuDsB;AAAK,aAAO,KAAK,OAAL,CAAa,MAAb,CAAoB,MAA3B;AAAoC;AAvD/D;AAAA;AAAA,wBAwD2B;AACnB,aAAO,KAAK,aAAL,KAAuB,KAAK,aAAL,GAAqB,mBAAmB,CAAC,OAApB,CAA4B,IAA5B,CAA5C,CAAP;AACH;AA1DL;AAAA;AAAA,yBASiF,OATjF,EAS8K;AACtK,UAAI,UAAU,CAAgC,OAAO,CAAC,QAAD,CAAvC,CAAd,EAAkE;AAC9D,eAAO,KAAK,CAAC,IAAN,CAAW,OAAX,CAAP;AACH;;AACD,aAAO,KAAK,CAAC,IAAN,CAAW,OAAX,CAAP;AACH;AAID;;AAlBJ;AAAA;AAAA,2BAmBiF;AAAA,yCAAX,IAAW;AAAX,QAAA,IAAW;AAAA;;AAAA,6BACxD,eAAe,CAAI,IAAJ,CADyC;AAAA;AAAA,UAClE,EADkE;AAAA,UAC9D,EAD8D;;AAEzE,UAAM,EAAE,GAAG,EAAE,CAAC,MAAH,CAAU,UAAC,CAAD;AAAA,eAAgC,CAAC,YAAY,MAA7C;AAAA,OAAV,CAAX;AACA,wBAAW,WAAX,qBAA0B,oBAAoB,CAAC,IAAI,MAAJ,CAAc,EAAd,CAAD,EAAoB,EAAE,CAAC,GAAH,CAAO,UAAC,CAAD;AAAA,eAAO,CAAC,CAAC,IAAT;AAAA,OAAP,CAApB,CAA9C;AACH;AAvBL;;AAAA;AAAA,EACY,YADZ;AAuEA;;;;;;;;;AAQA;;AACA,WAAa,oCAAb;AAAA;;AAAA;;AACI,gDAAY,MAAZ,EAA6B;AAAA;;AAAA,8BACnB,MADmB,EACX,CADW,EACR,MAAM,CAAC,MAAP,CAAc,GAAd,CAAkB,UAAC,CAAD;AAAA,aAAO,IAAI,CAAC,GAAL,CAAS,CAAC,CAAC,IAAX,EAAiB,CAAjB,EAAoB,CAApB,EAAuB,CAAvB,CAAP;AAAA,KAAlB,CADQ;AAE5B;;AAHL;AAAA,EAAuG,WAAvG;AAMA;;IACM,mB;;;;;AAAN,iCAAA;AAAA;;AAAA;;;AACW,WAAA,YAAA,GAAe,IAAI,GAAJ,EAAf;AADX;AAuBC;;;;0BAhBgB,I,EAAY,I,EAAc;AAAA;;AACnC,UAAI,QAAQ,CAAC,YAAT,CAAsB,IAAtB,CAAJ,EAAiC;AAC7B,eAAO,KAAK,eAAL,CAAqB,IAArB,EAA2B,IAA3B,CAAP;AACH,OAFD,MAEO;AACH,QAAA,IAAI,CAAC,SAAL,CAAe,OAAf,CAAuB,UAAC,KAAD,EAAQ,CAAR;AAAA,iBACnB,MAAI,CAAC,KAAL,CAAW,KAAX,EAAkB,IAAI,CAAC,QAAL,CAAc,CAAd,EAAiB,IAAnC,CADmB;AAAA,SAAvB;AAEH;;AACD,aAAO,IAAP;AACH;;;oCACsB,I,EAAY,I,EAAgB;AAC/C,UAAM,UAAU,GAAG,IAAI,CAAC,UAAxB;;AACA,UAAI,UAAU,IAAI,UAAU,CAAC,MAAX,GAAoB,CAAtC,EAAyC;AACrC,aAAK,YAAL,CAAkB,GAAlB,CAAsB,IAAI,CAAC,EAA3B,EAA+B,UAA/B;AACH;;AACD,aAAO,IAAP;AACH;;;4BApB4C,K,EAAQ;AACjD,aAAO,IAAI,mBAAJ,GAA0B,KAA1B,CACH,KAAK,CAAC,IADH,EACS,IAAI,MAAJ,CAAW,KAAK,CAAC,MAAN,CAAa,MAAxB,CADT,EAEL,YAFF;AAGH;;;;EAN6B,O","sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Data } from './data';\nimport { Table } from './table';\nimport { Vector } from './vector';\nimport { Visitor } from './visitor';\nimport { Schema, Field } from './schema';\nimport { isIterable } from './util/compat';\nimport { Chunked } from './vector/chunked';\nimport { selectFieldArgs } from './util/args';\nimport { DataType, Struct, Dictionary } from './type';\nimport { ensureSameLengthData } from './util/recordbatch';\nimport { Clonable, Sliceable, Applicative } from './vector';\nimport { StructVector, VectorBuilderOptions, VectorBuilderOptionsAsync } from './vector/index';\n\ntype VectorMap = { [key: string]: Vector };\ntype Fields<T extends { [key: string]: DataType }> = (keyof T)[] | Field<T[keyof T]>[];\ntype ChildData<T extends { [key: string]: DataType }> = (Data<T[keyof T]> | Vector<T[keyof T]>)[];\n\nexport interface RecordBatch<T extends { [key: string]: DataType } = any> {\n    concat(...others: Vector<Struct<T>>[]): Table<T>;\n    slice(begin?: number, end?: number): RecordBatch<T>;\n    clone(data: Data<Struct<T>>, children?: Vector[]): RecordBatch<T>;\n}\n\nexport class RecordBatch<T extends { [key: string]: DataType } = any>\n    extends StructVector<T>\n    implements Clonable<RecordBatch<T>>,\n               Sliceable<RecordBatch<T>>,\n               Applicative<Struct<T>, Table<T>> {\n\n    public static from<T extends { [key: string]: DataType } = any, TNull = any>(options: VectorBuilderOptions<Struct<T>, TNull>): Table<T>;\n    public static from<T extends { [key: string]: DataType } = any, TNull = any>(options: VectorBuilderOptionsAsync<Struct<T>, TNull>): Promise<Table<T>>;\n    /** @nocollapse */\n    public static from<T extends { [key: string]: DataType } = any, TNull = any>(options: VectorBuilderOptions<Struct<T>, TNull> | VectorBuilderOptionsAsync<Struct<T>, TNull>) {\n        if (isIterable<(Struct<T>)['TValue'] | TNull>(options['values'])) {\n            return Table.from(options as VectorBuilderOptions<Struct<T>, TNull>);\n        }\n        return Table.from(options as VectorBuilderOptionsAsync<Struct<T>, TNull>);\n    }\n\n    public static new<T extends VectorMap = any>(children: T): RecordBatch<{ [P in keyof T]: T[P]['type'] }>;\n    public static new<T extends { [key: string]: DataType } = any>(children: ChildData<T>, fields?: Fields<T>): RecordBatch<T>;\n    /** @nocollapse */\n    public static new<T extends { [key: string]: DataType } = any>(...args: any[]) {\n        const [fs, xs] = selectFieldArgs<T>(args);\n        const vs = xs.filter((x): x is Vector<T[keyof T]> => x instanceof Vector);\n        return new RecordBatch(...ensureSameLengthData(new Schema<T>(fs), vs.map((x) => x.data)));\n    }\n\n    protected _schema: Schema;\n    protected _dictionaries?: Map<number, Vector>;\n\n    constructor(schema: Schema<T>, length: number, children: (Data | Vector)[]);\n    constructor(schema: Schema<T>, data: Data<Struct<T>>, children?: Vector[]);\n    constructor(...args: any[]) {\n        let data: Data<Struct<T>>;\n        let schema = args[0] as Schema<T>;\n        let children: Vector[] | undefined;\n        if (args[1] instanceof Data) {\n            [, data, children] = (args as [any, Data<Struct<T>>, Vector<T[keyof T]>[]?]);\n        } else {\n            const fields = schema.fields as Field<T[keyof T]>[];\n            const [, length, childData] = args as [any, number, Data<T[keyof T]>[]];\n            data = Data.Struct(new Struct<T>(fields), 0, length, 0, null, childData);\n        }\n        super(data, children);\n        this._schema = schema;\n    }\n\n    public clone(data: Data<Struct<T>>, children = this._children) {\n        return new RecordBatch<T>(this._schema, data, children);\n    }\n\n    public concat(...others: Vector<Struct<T>>[]): Table<T> {\n        const schema = this._schema, chunks = Chunked.flatten(this, ...others);\n        return new Table(schema, chunks.map(({ data }) => new RecordBatch(schema, data)));\n    }\n\n    public get schema() { return this._schema; }\n    public get numCols() { return this._schema.fields.length; }\n    public get dictionaries() {\n        return this._dictionaries || (this._dictionaries = DictionaryCollector.collect(this));\n    }\n\n    public select<K extends keyof T = any>(...columnNames: K[]) {\n        const nameToIndex = this._schema.fields.reduce((m, f, i) => m.set(f.name as K, i), new Map<K, number>());\n        return this.selectAt(...columnNames.map((columnName) => nameToIndex.get(columnName)!).filter((x) => x > -1));\n    }\n    public selectAt<K extends T[keyof T] = any>(...columnIndices: number[]) {\n        const schema = this._schema.selectAt(...columnIndices);\n        const childData = columnIndices.map((i) => this.data.childData[i]).filter(Boolean);\n        return new RecordBatch<{ [key: string]: K }>(schema, this.length, childData);\n    }\n}\n\n/**\n * An internal class used by the `RecordBatchReader` and `RecordBatchWriter`\n * implementations to differentiate between a stream with valid zero-length\n * RecordBatches, and a stream with a Schema message, but no RecordBatches.\n * @see https://github.com/apache/arrow/pull/4373\n * @ignore\n * @private\n */\n/* tslint:disable:class-name */\nexport class _InternalEmptyPlaceholderRecordBatch<T extends { [key: string]: DataType } = any> extends RecordBatch<T> {\n    constructor(schema: Schema<T>) {\n        super(schema, 0, schema.fields.map((f) => Data.new(f.type, 0, 0, 0)));\n    }\n}\n\n/** @ignore */\nclass DictionaryCollector extends Visitor {\n    public dictionaries = new Map<number, Vector>();\n    public static collect<T extends RecordBatch>(batch: T) {\n        return new DictionaryCollector().visit(\n            batch.data, new Struct(batch.schema.fields)\n        ).dictionaries;\n    }\n    public visit(data: Data, type: DataType) {\n        if (DataType.isDictionary(type)) {\n            return this.visitDictionary(data, type);\n        } else {\n            data.childData.forEach((child, i) =>\n                this.visit(child, type.children[i].type));\n        }\n        return this;\n    }\n    public visitDictionary(data: Data, type: Dictionary) {\n        const dictionary = data.dictionary;\n        if (dictionary && dictionary.length > 0) {\n            this.dictionaries.set(type.id, dictionary);\n        }\n        return this;\n    }\n}\n"]},"metadata":{},"sourceType":"module"}